# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'b1.ui'
#
# Created by: PyQt5 UI code generator 5.15.4
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.

import sys
from GetLongitudeAndLatitude import Coordinate

import pandas as pd
from utils.datasets import *
from utils.utils import *
from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtGui import QIcon
from PyQt5.QtWidgets import *
from PyQt5.QtGui import *
from PyQt5.QtCore import *
from PyQt5.QtCore import Qt
import os
print(os.getenv('path'))
print(os.getcwd())
os.environ["CUDA_VISIBLE_DEVICES"] = "cpu"
os.environ['path'] = os.getcwd()+"\\lib;" + os.environ['path']
print(os.getenv('path'))

# from openvino.inference_engine import IENetwork,IECore
# from openvino.inference_engine import IECore

import cv2
import numpy as np
import onnxruntime
os.environ["PYTORCH_JIT"] = "0"

def script_method(fn, _rcb=None):
    return fn
def script(obj, optimize=True, _frames_up=0, _rcb=None):
    return obj

import torch.jit
script_method = torch.jit.script_method
script = torch.jit.script
torch.jit.script_method = script_method
torch.jit.script = script
import csv
import math
class Coordinate:
    # PHI       翻滚角
    # THETA     俯仰角
    # PSI       偏航角
    # ALTITUDE  海拔高度
    # JA        原点经度
    # WA        原点纬度
    F = 35.00000            # 焦距
    ER = 6378137.00000      # 赤道半径
    EJ = 6356725.00000      # 极半径
    PIXEL_SIZE = 0.00451    # 像元尺寸
    #
    # def __init__(self, PIC_NO):
    #
    #     with open('new.csv', 'r') as f:
    #         _csv_result = list(csv.reader(f))
    #     print(_csv_result)
    #     for row in _csv_result:
    #         if row[0] == PIC_NO:
    #             self.WA = float(row[2])
    #             self.JA = float(row[3])
    #             self.ALTITUDE = float(row[4])
    #             self.PHI = float(row[5])
    #             self.THETA = float(row[6])
    #             self.PSI = float(row[7])

    def __init__(self, ALTITUDE, JA, WA, PSI):
        self.WA = float(WA)
        self.JA = float(JA)
        self.ALTITUDE = float(ALTITUDE)
        self.PHI = 0
        self.THETA = 0
        self.PSI = float(PSI)

    def resetCoordinate(self, WA, JA, ALTITUDE, PHI, THETA, PSI):
        self.PHI = PHI
        self.THETA = THETA
        self.PSI = PSI
        self.ALTITUDE = ALTITUDE
        self.JA = JA
        self.WA = WA

    def XiangSuCoordinate(self, w, h, x, y):
        '''
            把以左上角为原点的像素坐标系 转换为以图像中心为原点的像素坐标系
            :param w: 图像宽
            :param h: 图像高
            :param x: 左上原点坐标系下x轴坐标
            :param y: 左上原点坐标系下y轴坐标
            :return:  中心原点坐标系下的x y 坐标
        '''
        w = w / 2
        h = h / 2
        x = math.floor(x - w)
        y = math.floor(h - y)
        return x, y

    def getLongitudeAndLatitude(self, X, Y):
        '''
                这个函数用来求像素点(X,Y)对应的经纬度
                :param X: 像素坐标系坐标X
                :param Y: 像素坐标系坐标Y
                :return:  经过转换之后的像素坐标坐标
                    坐标转换过程如下:
                    像素坐标系       机体坐标系        大地坐标系               像素坐标系
                    x    y          x    y           x    y      回到图像    x    y
                    3285,1870 ----> 1870 3285 ----> 3609 -1117  ---------> -1117 3609
                    406  1179 ----> 1179 406  ----> 651  -1063  ---------> -1063 651
            '''
        X, Y = Y, X  # 像素坐标系--->机体坐标系 需要交换X Y 的值
        R1 = np.array([[1, 0, 0],
                       [0, np.cos(np.deg2rad(self.PHI)), -np.sin(np.deg2rad(self.PHI))],
                       [0, np.sin(np.deg2rad(self.PHI)), np.cos(np.deg2rad(self.PHI))]])

        R2 = np.array([[np.cos(np.deg2rad(self.THETA)), 0, np.sin(np.deg2rad(self.THETA))],
                       [0, 1, 0],
                       [-np.sin(np.deg2rad(self.THETA)), 0, np.cos(np.deg2rad(self.THETA))]])

        R3 = np.array([[np.cos(np.deg2rad(self.PSI)), -np.sin(np.deg2rad(self.PSI)), 0],
                       [np.sin(np.deg2rad(self.PSI)), np.cos(np.deg2rad(self.PSI)), 0],
                       [0, 0, 1]])

        R_temp = R1.dot(R2)
        R = R_temp.dot(R3)
        #R = np.linalg.inv(R)

        # 机体坐标系----> 大地坐标系
        Alter = R.dot(np.array([[X], [Y], [0]]))
        # 大地坐标系----> 像素坐标系 交换 X Y 即可
        Xb, Yb = Alter[1], Alter[0]

        # Xb Yb则为最终的像素点坐标
        # L 为原点与Xb Yb之间的距离
        L = (Coordinate.PIXEL_SIZE / Coordinate.F) * self.ALTITUDE * np.sqrt((np.power(Xb, 2) + np.power(Yb, 2)))
        # angle 为原点与Xb Yb形成的方位角
        angle = 0.0
        x1, y1, x2, y2 = 0, 0, Xb, Yb
        dx = x2 - x1
        dy = y2 - y1
        if x2 == x1:
            angle = math.pi / 2.0
        if y2 == y1:
            angle = 0.0
        elif y2 < y1:
            angle = 3.0 * math.pi / 2.0
        elif x2 > x1 and y2 > y1:
            angle = math.atan(dx / dy)
        elif x2 > x1 and y2 < y1:
            angle = math.pi / 2 + math.atan(-dy / dx)
        elif x2 < x1 and y2 < y1:
            angle = math.pi + math.atan(dx / dy)
        elif x2 < x1 and y2 > y1:
            angle = 3.0 * math.pi / 2.0 + math.atan(dy / -dx)
        angle = angle * 180 / math.pi

        # dx: L向经度方向的投影
        # dy: L向纬度方向的投影
        dx = L * np.sin(np.deg2rad(angle))
        dy = L * np.cos(np.deg2rad(angle))
        ex = Coordinate.EJ + (Coordinate.ER - Coordinate.EJ) * (90 - self.WA) / 90
        ed = ex * np.cos((self.WA * np.pi / 180))
        Jb = dx / ed * 180 / np.pi + self.JA
        Wb = dy / ex * 180 / np.pi + self.WA
        print(Jb, Wb)
        return Jb, Wb


class ONNX(object):
    def __init__(self,onnx_path):
        '''初始化onnx'''
        self.onnx_session=onnxruntime.InferenceSession(onnx_path)
        print(onnxruntime.get_device())
        print(self.onnx_session.get_inputs()[0])
        self.input_name=self.get_input_name()
        self.output_name=self.get_output_name()
        self.classes=['psk']
    def get_input_name(self):
        '''获取输入节点名称'''
        input_name=[]
        for node in self.onnx_session.get_inputs():
            input_name.append(node.name)

        return input_name

    def get_output_name(self):
        '''获取输出节点名称'''
        output_name=[]
        for node in self.onnx_session.get_outputs():
            output_name.append(node.name)

        return output_name

    def get_input_feed(self,image_tensor):
        '''获取输入tensor'''
        input_feed={}
        for name in self.input_name:
            input_feed[name]=image_tensor

        return input_feed

    def letterbox(self,img, new_shape=(640, 640), color=(114, 114, 114), auto=False, scaleFill=False, scaleup=True,
                  stride=32):
        '''图片归一化'''
        # Resize and pad image while meeting stride-multiple constraints
        shape = img.shape[:2]  # current shape [height, width]
        if isinstance(new_shape, int):
            new_shape = (new_shape, new_shape)

        # Scale ratio (new / old)
        r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])
        if not scaleup:  # only scale down, do not scale up (for better test mAP)
            r = min(r, 1.0)

        # Compute padding
        ratio = r, r  # width, height ratios

        new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))
        dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding

        if auto:  # minimum rectangle
            dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding
        elif scaleFill:  # stretch
            dw, dh = 0.0, 0.0
            new_unpad = (new_shape[1], new_shape[0])
            ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios

        dw /= 2  # divide padding into 2 sides
        dh /= 2

        if shape[::-1] != new_unpad:  # resize
            img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)

        top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
        left, right = int(round(dw - 0.1)), int(round(dw + 0.1))

        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border
        return img, ratio, (dw, dh)

    def xywh2xyxy(self,x):
        # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right
        y = np.copy(x)

        y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x
        y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y
        y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x
        y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y

        return y

    def nms(self,prediction, conf_thres=0.1, iou_thres=0.6, agnostic=False):
        if prediction.dtype is torch.float16:
            prediction = prediction.float()  # to FP32
        xc = prediction[..., 4] > conf_thres  # candidates
        min_wh, max_wh = 2, 4096  # (pixels) minimum and maximum box width and height
        max_det = 300  # maximum number of detections per image
        output = [None] * prediction.shape[0]
        for xi, x in enumerate(prediction):  # image index, image inference
            x = x[xc[xi]]  # confidence
            if not x.shape[0]:
                continue

            x[:, 5:] *= x[:, 4:5]  # conf = obj_conf * cls_conf
            box = self.xywh2xyxy(x[:, :4])

            conf, j = x[:, 5:].max(1, keepdim=True)
            x = torch.cat((torch.tensor(box), conf, j.float()), 1)[conf.view(-1) > conf_thres]
            n = x.shape[0]  # number of boxes
            if not n:
                continue
            c = x[:, 5:6] * (0 if agnostic else max_wh)  # classes
            boxes, scores = x[:, :4] + c, x[:, 4]  # boxes (offset by class), scores
            i = torchvision.ops.boxes.nms(boxes, scores, iou_thres)
            if i.shape[0] > max_det:  # limit detections
                i = i[:max_det]
            output[xi] = x[i]

        return output

    def clip_coords(self,boxes, img_shape):
        '''查看是否越界'''
        # Clip bounding xyxy bounding boxes to image shape (height, width)
        boxes[:, 0].clamp_(0, img_shape[1])  # x1
        boxes[:, 1].clamp_(0, img_shape[0])  # y1
        boxes[:, 2].clamp_(0, img_shape[1])  # x2
        boxes[:, 3].clamp_(0, img_shape[0])  # y2

    def scale_coords(self,img1_shape, coords, img0_shape, ratio_pad=None):

        '''
        坐标对应到原始图像上，反操作：减去pad，除以最小缩放比例
        :param img1_shape: 输入尺寸
        :param coords: 输入坐标
        :param img0_shape: 映射的尺寸
        :param ratio_pad:
        :return:
        '''

        # Rescale coords (xyxy) from img1_shape to img0_shape
        if ratio_pad is None:  # calculate from img0_shape
            gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain  = old / new,计算缩放比率
            pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (
                        img1_shape[0] - img0_shape[0] * gain) / 2  # wh padding ，计算扩充的尺寸
        else:
            gain = ratio_pad[0][0]
            pad = ratio_pad[1]

        coords[:, [0, 2]] -= pad[0]  # x padding，减去x方向上的扩充
        coords[:, [1, 3]] -= pad[1]  # y padding，减去y方向上的扩充
        coords[:, :4] /= gain  # 将box坐标对应到原始图像上
        self.clip_coords(coords, img0_shape)  # 边界检查
        return coords

    def sigmoid(self,x):
        return 1 / (1 + np.exp(-x))

    def infer(self,img_path,output):
        '''执行前向操作预测输出'''
        # base = os.path.basename(img_path)
        # base = os.path.splitext(base)[0]
        # print('base:', base)
        # print('base[5:]:', base[5:])
        # coordinate1 = Coordinate(base[5:])
        # base = os.path.basename(img_path)
        # base = os.path.splitext(base)[0]
        # ALTITUDE, JA, WA, PSI = random.randint(200, 500), random.randint(0, 180), random.randint(0,180), random.randint(0,90),
        # coordinate1 = Coordinate(ALTITUDE, JA, WA, PSI)
        # 超参数设置
        img_size=(640,640) #图片缩放大小
        # 读取图片
        src_img=cv2.imread(img_path)
        start=time.time()
        src_size=src_img.shape[:2]

        # 图片填充并归一化
        img=self.letterbox(src_img,img_size,stride=32)[0]

        # Convert
        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416
        img = np.ascontiguousarray(img)

        # 归一化
        img=img.astype(dtype=np.float32)
        img/=255.0

        # # BGR to RGB
        # img = img[:, :, ::-1].transpose(2, 0, 1)
        # img = np.ascontiguousarray(img)

        # 维度扩张 (3, 640, 640)->(1, 3, 640, 640)
        img=np.expand_dims(img,axis=0)
        print('img resuming: ', time.time()-start)
        # 前向推理
        # start=time.time()
        input_feed=self.get_input_feed(img)
        # ort_inputs = {self.onnx_session.get_inputs()[0].name: input_feed[None].numpy()}
        # pdb.set_trace()
        # pred.shape --> torch.Size([1, 25200, 6])
        pred = torch.tensor(self.onnx_session.run(None, input_feed)[0])
        # results(list) --> results[0].shape --> torch.Size([8, 6])
        print('pred',pred.shape)
        results = non_max_suppression(pred, 0.25,0.5)
        print('onnx resuming: ', time.time()-start)
        # pred=self.onnx_session.run(output_names=self.output_name,input_feed=input_feed)

        #映射到原始图像
        img_shape=img.shape[2:]
        # print(img_size)
        info = ''
        for det in results:  # detections per image
            if det is not None and len(det):
                info += '疑似检测排水口个数为：{:d}个\n'.format(det.shape[0])
                # det从(640，640）-->原始图片大小的坐标映射
                det[:, :4] = self.scale_coords(img_shape, det[:, :4],src_size).round()
                for *xyxy, conf, cls in reversed(det):
                    int_xyxy = [int(j) for j in xyxy]
                    # cx, cy = coordinate1.XiangSuCoordinate(src_img.shape[1], src_img.shape[0], int_xyxy[0], int_xyxy[1])
                    # jb, wb = coordinate1.getLongitudeAndLatitude(cx, cy)
                    info += '左上角坐标 ({:d} {:d}) ,右下角坐标 ({:d} {:d})\n'.format(*int_xyxy)
                    # info += '经度 ({:.3f}) \n纬度 ({:.3f})\n\n'.format(jb[0], wb[0])

                print(info)
        print(time.time()-start)
        if det is not None and len(det):
            self.draw(src_img, det, output)
        return pred, conf, det
    def plot_one_box(self,x, img, color=None, label=None, line_thickness=None):
        # Plots one bounding box on image img
        tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness
        color = color or [random.randint(0, 255) for _ in range(3)]
        c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))
        cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)
        if label:
            tf = max(tl - 1, 1)  # font thickness
            t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]
            c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3
            cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled
            cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)

    def draw(self,img, boxinfo, output):
        colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(self.classes))]
        for *xyxy, conf, cls in boxinfo:
            label = '%s %.2f' % (self.classes[int(cls)], conf)
            # print('xyxy: ', xyxy)
            self.plot_one_box(xyxy, img, label=label, color=colors[int(cls)], line_thickness=1)

        # cv2.namedWindow("dst",0)
        # cv2.imshow("dst", img)
        cv2.imwrite(output,img)
        # cv2.waitKey(0)
        # cv2.imencode('.jpg', img)[1].tofile(os.path.join(dst, id + ".jpg"))
        return 0

def load_model(path):
    ONNX(onnx_path=path)
    # model_xml = path
    # model_bin = os.path.splitext(model_xml)[0] + ".bin"
    # print('begin IE core')
    # ie = IECore()
    #
    # print('loading model...')
    # net = ie.read_network(model=model_xml, weights=model_bin)
    # print('loaded model!')
    #
    # input_blob = next(iter(net.inputs))
    # out_blobs = net.outputs.keys()
    # net.batch_size = 1
    #
    # exec_net = ie.load_network(network=net, device_name="CPU")
    # return exec_net, input_blob, out_blobs

def get_image_list(img):
    # img = cv2.resize(img, [1378, 480])
    data = []
    # print('img.shape',img.shape)
    x_shape = img.shape[1] / 7
    y_shape = img.shape[0] / 3
    for j in range(3):
        A = []
        for i in range(7):
            x1, y1 = int(x_shape * i), int(y_shape * j)
            x2, y2 = int(x_shape * (i + 1)), int(y_shape * (j + 1))
            per_image = img[y1:y2, x1:x2]
            A.append(per_image)
            # print('per_image.shape', per_image.shape)
        data.append(A)
        # print('len(A):',len(A))

    return data

def regulate_bbx(pre_bbx, num, x_shape, y_shape):
    # x_shape, y_shape = 1136, 1768
    y_new, x_new = num[0], num[1]
    c1_x, c1_y = pre_bbx[0], pre_bbx[1]
    c2_x, c2_y = pre_bbx[2], pre_bbx[3]
    c1_x = c1_x + x_new * x_shape
    c1_y = c1_y + y_new * y_shape
    c2_x = c2_x + x_new * x_shape
    c2_y = c2_y + y_new * y_shape
    return c1_x, c1_y, c2_x, c2_y

def is_number(s):
    try:
        float(s)
        return True
    except ValueError:
        pass

    try:
        import unicodedata
        unicodedata.numeric(s)
        return True
    except (TypeError, ValueError):
        pass

    return False

class Ui_MainWindow(QWidget):
    def setupUi(self, MainWindow):

        self.save = False
        self.push3 = False
        self.clik = True
        self.n = 0
        self.a = True  # 表示检测是否执行
        MainWindow.setObjectName("MainWindow")
        MainWindow.resize(832, 636)

        self.centralwidget = QtWidgets.QWidget(MainWindow)
        self.centralwidget.setObjectName("centralwidget")
        self.gridLayout_2 = QtWidgets.QGridLayout(self.centralwidget)
        self.gridLayout_2.setObjectName("gridLayout_2")
        self.verticalLayout_2 = QtWidgets.QVBoxLayout()
        self.verticalLayout_2.setObjectName("verticalLayout_2")
        self.label = QtWidgets.QLabel(self.centralwidget)
        self.label.setObjectName("label")
        self.verticalLayout_2.addWidget(self.label)
        self.verticalLayout = QtWidgets.QVBoxLayout()
        self.verticalLayout.setObjectName("verticalLayout")
        self.horizontalLayout_2 = QtWidgets.QHBoxLayout()
        self.horizontalLayout_2.setObjectName("horizontalLayout_2")

        self.labelImage = draw_Label(self.centralwidget, self)
        # self.labelImage.setScaledContents (True)
        self.pixmap = QPixmap('')
        # self.scaled_img = self.pixmap.scaled(self.size())
        self.labelImage.setPixmap(self.pixmap)
        self.labelImage.setFrameShape(QtWidgets.QFrame.Box)
        self.labelImage.setFrameShadow(QtWidgets.QFrame.Raised)
        self.labelImage.setStyleSheet('background-color: rgb(200, 200, 200)')
        self.labelImage.setObjectName("graphicsView")
        self.labelImage.setMinimumSize(QtCore.QSize(541, 411))
        self.horizontalLayout_2.addWidget(self.labelImage)

        self.gridLayout = QtWidgets.QGridLayout()
        self.gridLayout.setObjectName("gridLayout")
        # 检测进度
        self.label_2 = QtWidgets.QLabel(self.centralwidget)
        self.label_2.setObjectName("label_2")
        self.gridLayout.addWidget(self.label_2, 0, 0, 1, 1)
        self.progressBar = QtWidgets.QProgressBar(self.centralwidget)
        self.progressBar.setProperty("value", 24)
        self.progressBar.setObjectName("progressBar")
        self.progressBar.setRange(0, 100)
        # 设置进度条的初始值
        self.progressBar.setValue(0)
        # 设置定时器（走进度条的时候需要使用，否则进度条不会变化，而是固定不变
        self.timer = QBasicTimer()
        # self.step = 0

        self.gridLayout.addWidget(self.progressBar, 0, 1, 1, 1)
        # 响应系数
        self.label_3 = QtWidgets.QLabel(self.centralwidget)
        self.label_3.setObjectName("label_3")
        self.gridLayout.addWidget(self.label_3, 1, 0, 1, 1)
        self.cb =QComboBox()
        # self.cb.addItem('0.3')
        # self.cb.addItem('Python')
        self.cb.addItems(['0.1', '0.3', '0.5', '0.6', '0.7', '0.8'])
        self.cb.setCurrentIndex(1)
        # aa = self.cb.currentText()
        # print(aa)
        self.gridLayout.addWidget(self.cb, 1, 1, 1, 1)

        # self.lineEdit_6 = QtWidgets.QLineEdit(self.centralwidget)
        # self.lineEdit_6.setObjectName("lineEdit_6")
        # self.gridLayout.addWidget(self.lineEdit_6, 1, 1, 1, 1)
        # 图像文件名
        self.label_4 = QtWidgets.QLabel(self.centralwidget)
        self.label_4.setObjectName("label_4")
        self.gridLayout.addWidget(self.label_4, 2, 0, 1, 1)
        self.label_7 = QtWidgets.QLabel(self.centralwidget)
        self.label_7.setObjectName("label_7")
        self.gridLayout.addWidget(self.label_7, 2, 1, 1, 1)
        # 疑似检测数量
        self.label_5 = QtWidgets.QLabel(self.centralwidget)
        self.label_5.setObjectName("label_5")
        self.gridLayout.addWidget(self.label_5, 3, 0, 1, 1)
        self.lineEdit_3 = QtWidgets.QLineEdit(self.centralwidget)
        self.lineEdit_3.setReadOnly(True)
        self.lineEdit_3.setObjectName("lineEdit_3")
        self.gridLayout.addWidget(self.lineEdit_3, 3, 1, 1, 1)
        # 检测结果
        self.label_6 = QtWidgets.QLabel(self.centralwidget)
        self.label_6.setObjectName("label_6")
        self.gridLayout.addWidget(self.label_6, 4, 0, 1, 1)
        self.textEdit = QtWidgets.QTextEdit(self.centralwidget)
        self.textEdit.setReadOnly(True)
        self.textEdit.setObjectName("textEdit")
        self.gridLayout.addWidget(self.textEdit, 5, 0, 1, 2)
        self.horizontalLayout_2.addLayout(self.gridLayout)
        # 设置比例
        self.horizontalLayout_2.setStretch(0, 3)
        self.horizontalLayout_2.setStretch(1, 1)
        self.verticalLayout.addLayout(self.horizontalLayout_2)
        self.horizontalLayout = QtWidgets.QHBoxLayout()
        self.horizontalLayout.setObjectName("horizontalLayout")
        # 控件部分
        self.pushButton = QtWidgets.QPushButton(self.centralwidget)
        self.pushButton.setObjectName("pushButton")
        self.pushButton.clicked.connect(self.openimage)
        self.horizontalLayout.addWidget(self.pushButton)
        self.pushButton_2 = QtWidgets.QPushButton(self.centralwidget)
        self.pushButton_2.setObjectName("pushButton_2")
        self.pushButton_2.clicked.connect(self.openfile)
        self.horizontalLayout.addWidget(self.pushButton_2)
        self.pushButton_3 = QtWidgets.QPushButton(self.centralwidget)
        self.pushButton_3.setObjectName("pushButton_3")
        self.pushButton_3.clicked.connect(self.predict)
        self.horizontalLayout.addWidget(self.pushButton_3)
        self.pushButton_4 = QtWidgets.QPushButton(self.centralwidget)
        self.pushButton_4.setObjectName("pushButton_4")
        self.pushButton_4.clicked.connect(self.clearfile)
        self.horizontalLayout.addWidget(self.pushButton_4)
        self.pushButton_5 = QtWidgets.QPushButton(self.centralwidget)
        self.pushButton_5.setObjectName("pushButton_5")
        self.pushButton_5.clicked.connect(self.btn_save)
        self.horizontalLayout.addWidget(self.pushButton_5)
        self.verticalLayout.addLayout(self.horizontalLayout)
        self.verticalLayout_2.addLayout(self.verticalLayout)
        self.gridLayout_2.addLayout(self.verticalLayout_2, 0, 0, 1, 1)




        MainWindow.setCentralWidget(self.centralwidget)
        self.menubar = QtWidgets.QMenuBar(MainWindow)
        self.menubar.setGeometry(QtCore.QRect(0, 0, 832, 24))
        self.menubar.setObjectName("menubar")
        MainWindow.setMenuBar(self.menubar)
        self.statusbar = QtWidgets.QStatusBar(MainWindow)
        self.statusbar.setObjectName("statusbar")
        MainWindow.setStatusBar(self.statusbar)

        self.retranslateUi(MainWindow)
        QtCore.QMetaObject.connectSlotsByName(MainWindow)
    # 预测按钮变化
    def onStart(self):
        self.pushButton_3.setText("     请稍后     ")
        self.pushButton_3.setEnabled(False)
        self.pushButton_3.setText("预测中...")
        print("预测中......................................................................")
        self.timer.start(5, self)
    # 开始检测
    def predict(self):
        # self.labelImage.releaseKeyboard()  # 停止捕获键盘
        # 响应系数输入部分
        # def is_number(str):
        #     pattern = re.compile(r'^[-+]?[-0-9]\d*\.\d*|[-+]?\.?[0-9]\d*$')
        #     result = pattern.match(str)
        #     if result:
        #         return True
        #     else:
        #         return False
        # # a = self.lineEdit_6.text()
        # a = self.cb.currentText()
        # print('获取相应系数',a)
        # if a == '' or is_number(a) == False:
        #     self.error_dialog = QtWidgets.QErrorMessage()
        #     self.error_dialog.showMessage('请在响应系数中输入0～1的数字!')
        # else:
        #     if float(a) < 0 or float(a) > 1:
        #         self.error_dialog = QtWidgets.QErrorMessage()
        #         self.error_dialog.showMessage('请输入0～1的数字!')
        #     else:
        #         print(a)
        if self.push3 == False:
            if a1 == False:
                print('请载入图片!')
                self.error_dialog = QtWidgets.QErrorMessage()
                self.error_dialog.showMessage('请载入图片!')
            else:
                print('predict.......')
                print('creating model...')
                self.model = ONNX(onnx_path="super_resolution.onnx")
                # self.model.infer(r'1.jpg')
                print('created model!')

                if os.path.exists('template')==False:
                    os.mkdir('template')
                self.onStart()
                self.process()

                self.save = True
                self.a = False
    # 检测过程（BBox）

    # def process1(self):
    #     if self.opened:
    #         print(len(imgName))
    #         if len(imgName) > 2:
    #             imglist = []
    #             img_matlist = []
    #             for k in range(len(imgName)):
    #                 print(imgName[k], os.path.exists(imgName[k]))
    #                 img0 = cv2.imdecode(np.fromfile(imgName[k], dtype=np.uint8), cv2.IMREAD_COLOR)
    #                 print('read_img end!')
    #                 img_mat = get_image_list(img0.copy())
    #                 imglist.append(img0)
    #                 img_matlist.append(img_mat)
    #                 # print(len(img_mat), len(img_mat[0]))
    #                 detected_num = 0
    #                 gxyxy = []
    #
    #                 self.labelImage.set_bbox(det_list)
    #                 if det_list is not None and len(det_list):
    #                     num = 0
    #                     for obj_indx, (*xyxy, conf, cls) in enumerate(det_list):
    #                         detected_num += 1
    #                         num += 1
    #                         gxyxy.append(xyxy)
    #                         label = str(num)
    #                         plot_one_box(xyxy, imglist[k], label=label, color=(0, 0, 255), line_thickness=3)
    #                         cv2.imwrite('processed_{:d}.jpg'.format(k), imglist[k])
    #             # 检测结果显示
    #             # pdb.set_trace()
    #             info = '序号 排水口位置 排水口经纬度\n'
    #             for i in range(len(det_list)):
    #                 info += '{:d}  '.format(i + 1)
    #                 info += 'X:{0},Y:{1},W:{2},H:{3}\n'.format(gxyxy[i][0], gxyxy[i][1], gxyxy[i][2], gxyxy[i][3])
    #             self.textEdit.setText(info)
    #             self.lineEdit_3.setText(str(len(det_list)))
    #
    #             # self.detect_num.setText(str(detected_num))
    #             cv2.imwrite('processed.jpg', imglist[0])
    #             # self.detect_info.setText(info)
    #             # 显示图片
    #             self.pixmap = QPixmap('processed.jpg')
    #             self.labelImage.setPixmap(self.pixmap)
    #             # self.labelImage.setPixmap(QPixmap(label_image))#设置显示图片
    #             print('process end!')
    #         else:
    #             print('单张图片检测开始')
    #             print(self.path)
    #             base = os.path.basename(self.path)
    #             base = os.path.splitext(base)[0]
    #             ALTITUDE, JA, WA, PSI = random.randint(200, 500), random.randint(0, 180), random.randint(0,180), random.randint(0, 90),
    #             # print(base)
    #             # coordinate1 = Coordinate(base[5:])
    #             coordinate1 = Coordinate(ALTITUDE, JA, WA, PSI)
    #
    #             img0 = cv2.imdecode(np.fromfile(self.path, dtype=np.uint8), cv2.IMREAD_COLOR)
    #             img_mat = get_image_list(img0.copy())
    #             # print(len(img_mat), len(img_mat[0]))
    #             info = ''
    #             detected_num = 0
    #             inxy = []
    #             j, w = [], []
    #             for cc, col in enumerate(img_mat):
    #                 for rr, row in enumerate(col):
    #                     detect_shape = (640, 640)  # 图片缩放大小
    #                     img, ratio, (dw, dh) = letterbox(row.copy(), detect_shape, color=(0, 0, 0), auto=False)
    #                     # Convert
    #                     img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416
    #                     img = np.ascontiguousarray(img)
    #                     inputs = img.astype(np.float32)
    #                     inputs = inputs / 255
    #                     if len(inputs.shape) == 3:
    #                         inputs = np.expand_dims(inputs, 0)
    #                     # 读取图片
    #                     # src_img = cv2.imread(imgName)
    #                     # inputs = src_img.shape[:2]
    #                     # 图片填充并归一化
    #                     # img = self.letterbox(src_img, img_size, stride=32)[0]
    #                     # Convert
    #                     # img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416
    #                     # img = np.ascontiguousarray(img)
    #                     # 归一化
    #                     # img = img.astype(dtype=np.float32)
    #                     # img /= 255.0
    #                     # 维度扩张 (3, 640, 640)->(1, 3, 640, 640)
    #                     # img = np.expand_dims(img, axis=0)
    #                     input_feed = self.model.get_input_feed(inputs)
    #
    #                     pred = torch.tensor(self.model.onnx_session.run(None, input_feed)[0])
    #                     conf_in = self.lineEdit_6.text()
    #                     if is_number(conf_in) and float(conf_in) < 1 and float(conf_in) > 0:
    #                         confidence = float(conf_in)
    #                     else:
    #                         confidence = 0.4
    #                     pred = non_max_suppression(pred, confidence, 0.6,
    #                                                fast=True)
    #                     # results = non_max_suppression(pred, 0.25, 0.5)
    #                     # 映射到原始图像
    #                     # img_shape = img.shape[2:]
    #                     # # print(img_size)
    #                     # info = ''
    #                     # for det in results:  # detections per image
    #                     #     if det is not None and len(det):
    #                     #         info += '疑似检测排水口个数为：{:d}个\n'.format(det.shape[0])
    #                     #         # det从(640，640）-->原始图片大小的坐标映射
    #                     #         det[:, :4] = self.scale_coords(img_shape, det[:, :4], src_size).round()
    #                     #         for *xyxy, conf, cls in reversed(det):
    #                     #             int_xyxy = [int(j) for j in xyxy]
    #                     #             cx, cy = coordinate1.XiangSuCoordinate(src_img.shape[1], src_img.shape[0],
    #                     #                                                    int_xyxy[0], int_xyxy[1])
    #                     #             jb, wb = coordinate1.getLongitudeAndLatitude(cx, cy)
    #                     #             info += '左上角坐标 ({:d} {:d}) ,右下角坐标 ({:d} {:d})\n'.format(*int_xyxy)
    #                     #             info += '经度 ({:.3f}) \n纬度 ({:.3f})\n\n'.format(jb[0], wb[0])
    #                     for i, det in enumerate(pred):  # detections per image (i表示图片)
    #                         # det = [[100, 100, 200, 200, 0, 0]]
    #                         if det is not None and len(det):
    #                             # Rescale boxes from img_size to im0 size
    #                             # print(det)
    #                             det[:, :4] = scale_coords(inputs.shape[2:], det[:, :4], row.shape).round()
    #                             print('det', det[:, :4])
    #                             # Write results
    #                             for obj_indx, (*xyxy, conf, cls) in enumerate(det):
    #                                 # print(xyxy, [cc, rr])
    #                                 int_xyxy = [int(j) for j in xyxy]
    #                                 # label = '%s' % ('')
    #                                 label = str(detected_num + 1)
    #                                 # plot_one_box(int_xyxy, row, label=label, color=(0, 255, 0), line_thickness=3)
    #                                 # cv2.imwrite(str(cc)+'_'+str(rr)+'.jpg', row)
    #                                 # print(int_xyxy, [cc, rr])
    #                                 int_xyxy = regulate_bbx(int_xyxy, [cc, rr], row.shape[1], row.shape[0])
    #                                 det_list.append(list(int_xyxy))
    #                                 conf_list.append(conf * 100)
    #                                 detected_num += 1
    #                                 info += '排水口{:d}位置：\n'.format(detected_num)
    #                                 cx, cy = coordinate1.XiangSuCoordinate(img0.shape[1], img0.shape[0], int_xyxy[0],
    #                                                                        int_xyxy[1])
    #
    #                                 jb, wb = coordinate1.getLongitudeAndLatitude(cx, cy)
    #
    #                                 jb_list.append(jb)
    #                                 wb_list.append(wb)
    #
    #                                 info += '左上角坐标 ({:d} {:d}) \n右下角坐标 ({:d} {:d})\n'.format(*int_xyxy)
    #                                 info += '经度 ({:.3f}) \n纬度 ({:.3f})\n'.format(jb[0], wb[0])
    #                                 info += '置信度：{:.4f}%\n\n'.format(conf * 100)
    #                                 print('int_xyxy', int_xyxy)
    #                                 inxy.append(int_xyxy)
    #                                 j.append(jb[0])
    #                                 w.append(wb[0])
    #                                 plot_one_box(int_xyxy, img0, label=label, color=(0, 0, 255), line_thickness=3)
    #
    #             # 保存csv
    #             b = []
    #             c = []
    #             for z in range(len(inxy)):
    #                 b.append(z + 1)
    #                 c.append(inxy[z])
    #             dataframe = pd.DataFrame({'疑似排水口数量': detected_num, '排水口序号': b, '图像中排水口位置': c, '排水口经度': j, '排水口纬度': w})
    #             dataframe.to_csv(os.path.basename(self.path).split('.')[0] + '.csv', index=False, sep=',',
    #                              encoding='gbk')
    #             print('保存完毕')
    #
    #             self.lineEdit_3.setText(str(detected_num))
    #             cv2.imwrite('processed.jpg', img0)
    #             self.textEdit.setText(info)
    #             self.pixmap = QPixmap('processed.jpg')
    #             # self.scaled_img = self.pixmap.scaled(self.size())
    #             # self.labelImage.setPixmap(self.pixmap)
    #             self.labelImage.setPixmap(self.pixmap)
    #             # self.labelImage.repaint()
    #             self.labelImage.set_pic()
    #             # self.labelImage.setPixmap(QPixmap(label_image))#设置显示图片
    #             print('process end!')

    def process(self):
        if self.opened:
            # print('creating model...')
            # self.model, self.input_blob, self.out_blobs = load_model('super_resolution.xml')
            # print('created model!')
            # 批量图片检测
            print('len(imgName)',len(imgName))
            print('imgName',imgName)
            if len(imgName) > 1:
                self.step = 99
                global names
                names = globals()
                for k in range(len(imgName)):
                    abc = []
                    confabc = []
                    jbabc = []
                    wbabc = []
                    # exec('var{} = {}'.format(i, i))
                    # exec('print(var{}, end=" ")'.format(k))
                    print(imgName[k], os.path.exists(imgName[k]))
                    ALTITUDE, JA, WA, PSI = random.randint(200, 500), random.randint(0, 180), random.randint(0,180), random.randint(0, 90),
                    coordinate1 = Coordinate(ALTITUDE, JA, WA, PSI)

                    img0 = cv2.imdecode(np.fromfile(imgName[k], dtype=np.uint8), cv2.IMREAD_COLOR)
                    print('read_img{:d} end!'.format(k+1))
                    img_mat = get_image_list(img0.copy())
                    print('img_mat',len(img_mat))
                    print('img_mat',img_mat)
                    info = ''
                    detected_num = 0
                    inxy = []
                    j, w = [], []
                    for cc, col in enumerate(img_mat):
                        for rr, row in enumerate(col):
                            detect_shape = (640, 640)
                            # img, sp = self.resize_pad(row.copy(), detect_shape[0])
                            img, ratio, (dw, dh) = letterbox(row.copy(), detect_shape, color=(0, 0, 0), auto=False)
                            # Convert
                            img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416
                            img = np.ascontiguousarray(img)
                            inputs = img.astype(np.float32)
                            inputs = inputs / 255
                            # print('end!')
                            # print(inputs)
                            if len(inputs.shape) == 3:
                                inputs = np.expand_dims(inputs, 0)
                            input_feed = self.model.get_input_feed(inputs)

                            pred = torch.tensor(self.model.onnx_session.run(None, input_feed)[0])
                            # conf_in = self.lineEdit_6.text()
                            conf_in = self.cb.currentText()
                            if is_number(conf_in) and float(conf_in) < 1 and float(conf_in) > 0:
                                confidence = float(conf_in)
                            else:
                                confidence = 0.4
                            pred = non_max_suppression(pred, confidence, 0.6,fast=True)

                            for i, det in enumerate(pred):  # detections per image (i表示图片)
                                # det = [[100, 100, 200, 200, 0, 0]]
                                if det is not None and len(det):
                                    # Rescale boxes from img_size to im0 size
                                    # print(det)
                                    det[:, :4] = scale_coords(inputs.shape[2:], det[:, :4], row.shape).round()
                                    print('det', det[:, :4])
                                    # Write results
                                    for obj_indx, (*xyxy, conf, cls) in enumerate(det):
                                        # print(xyxy, [cc, rr])
                                        int_xyxy = [int(j) for j in xyxy]
                                        # label = '%s' % ('')
                                        label = str(detected_num + 1)
                                        # plot_one_box(int_xyxy, row, label=label, color=(0, 255, 0), line_thickness=3)
                                        # cv2.imwrite(str(cc)+'_'+str(rr)+'.jpg', row)
                                        # print(int_xyxy, [cc, rr])
                                        int_xyxy = regulate_bbx(int_xyxy, [cc, rr], row.shape[1], row.shape[0])
                                        det_list.append(list(int_xyxy))
                                        abc.append(list(int_xyxy))
                                        confabc.append(conf * 100)
                                        detected_num += 1
                                        info += 'Location Of The Outfall{:d}：\n'.format(detected_num)
                                        cx, cy = coordinate1.XiangSuCoordinate(img0.shape[1], img0.shape[0], int_xyxy[0], int_xyxy[1])
                                        jb, wb = coordinate1.getLongitudeAndLatitude(cx, cy)
                                        jbabc.append(jb)
                                        wbabc.append(wb)
                                        info += 'TL Coordinates ({:d} {:d}) \nBR Coordinates ({:d} {:d})\n'.format(*int_xyxy)
                                        info += 'Longitude ({:.3f}) \nLatitude ({:.3f})\n'.format(jb[0], wb[0])
                                        info += 'Confidence：{:.4f}%\n\n'.format(conf * 100)
                                        print('int_xyxy', int_xyxy)
                                        inxy.append(int_xyxy)
                                        j.append(jb[0])
                                        w.append(wb[0])
                                        plot_one_box(int_xyxy, img0, label=label, color=(0, 0, 255), line_thickness=3)
                    names['det_list_' + str(k)] = abc
                    names['conf_list_' + str(k)] = confabc
                    names['jb_list_' + str(k)] = jbabc
                    names['wb_list_' + str(k)] = wbabc
                    names['info_list_' + str(k)] = info
                    info_list.append(info)
                    detected_num_list.append(detected_num)
                    print('info_list',info_list)
                    print('detected_num_list',detected_num_list)
                    cv2.imwrite('template/processed_{:d}.jpg'.format(k + 1), img0)

                    # 保存csv
                    b = []
                    c = []
                    if len(inxy)==0:
                        b.append(0)
                        c.append(0)
                        j.append(0)
                        w.append(0)
                    else:
                        for z in range(len(inxy)):
                            b.append(z+1)
                            c.append(inxy[z])
                    # if detected_num != 0:
                    dataframe = pd.DataFrame({'疑似排水口数量': detected_num, '排水口序号': b, '图像中排水口位置': c, '排水口经度': j, '排水口纬度': w})
                    dataframe.to_csv('template/'+os.path.basename(imgName[k]).split('.')[0] + '.csv', index=False,sep=',', encoding='gbk')
                    print('保存完毕')
                    aa = (k+1)/len(imgName)
                    print('aa',aa)
                    bb = aa * 100
                    print('bb',bb)
                    # self.progressBar.setValue(100 * k/len(imgName))
                    self.progressBar.setValue(int(bb))




                self.lineEdit_3.setText(str(detected_num_list[0]))
                self.textEdit.setText(info_list[0])
                self.pixmap = QPixmap('template/processed_{:d}.jpg'.format(1))
                # self.scaled_img = self.pixmap.scaled(self.size())
                # self.labelImage.setPixmap(self.pixmap)
                self.labelImage.setPixmap(self.pixmap)
                self.labelImage.set_pic()
                # self.labelImage.setPixmap(QPixmap(label_image))#设置显示图片
                print('process end!')
            # 单张图片检测
            else:
                self.step = 0
                print('单张图片检测开始')
                print(self.path)
                base = os.path.basename(self.path)
                base = os.path.splitext(base)[0]
                ALTITUDE, JA, WA, PSI = random.randint(200, 500), random.randint(0, 180), random.randint(0,
                                                                                                         180), random.randint(
                    0, 90),
                # print(base)
                # coordinate1 = Coordinate(base[5:])
                coordinate1 = Coordinate(ALTITUDE, JA, WA, PSI)

                img0 = cv2.imdecode(np.fromfile(self.path, dtype=np.uint8), cv2.IMREAD_COLOR)
                img_mat = get_image_list(img0.copy())
                # print(len(img_mat), len(img_mat[0]))
                info = ''
                detected_num = 0
                inxy = []
                j, w = [], []
                for cc, col in enumerate(img_mat):
                    # print('cc', cc)
                    # print('col', col)
                    for rr, row in enumerate(col):
                        # print('rr', rr)
                        # print('row', row)
                        # print('row.shape',row.shape)
                        # cv2.imwrite('{:d}{:d}.jpg'.format(cc,rr),row)
                        detect_shape = (640, 640)  # 图片缩放大小
                        img, ratio, (dw, dh) = letterbox(row.copy(), detect_shape, color=(0, 0, 0), auto=False)
                        # Convert
                        # cv2.imwrite('img{:d}{:d}.jpg'.format(cc, rr), img)
                        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416
                        img = np.ascontiguousarray(img)
                        inputs = img.astype(np.float32)
                        inputs = inputs / 255
                        if len(inputs.shape) == 3:
                            inputs = np.expand_dims(inputs, 0)
                        # 读取图片

                        input_feed = self.model.get_input_feed(inputs)

                        pred = torch.tensor(self.model.onnx_session.run(None, input_feed)[0])
                        conf_in = self.cb.currentText()
                        if is_number(conf_in) and float(conf_in) < 1 and float(conf_in) > 0:
                            confidence = float(conf_in)
                        else:
                            confidence = 0.4
                        pred = non_max_suppression(pred, confidence, 0.6,
                                                   fast=True)

                        for i, det in enumerate(pred):  # detections per image (i表示图片)
                            # det = [[100, 100, 200, 200, 0, 0]]
                            if det is not None and len(det):
                                # Rescale boxes from img_size to im0 size
                                # print(det)
                                det[:, :4] = scale_coords(inputs.shape[2:], det[:, :4], row.shape).round()
                                # print('output-det[:, :4]', det[:, :4])
                                # Write results
                                for obj_indx, (*xyxy, conf, cls) in enumerate(det):
                                    # print(xyxy, [cc, rr])
                                    int_xyxy = [int(j) for j in xyxy]
                                    # label = '%s' % ('')
                                    label = str(detected_num + 1)
                                    # plot_one_box(int_xyxy, row, label=label, color=(0, 255, 0), line_thickness=3)
                                    # cv2.imwrite(str(cc)+'_'+str(rr)+'.jpg', row)
                                    # print(int_xyxy, [cc, rr])
                                    int_xyxy = regulate_bbx(int_xyxy, [cc, rr], row.shape[1], row.shape[0])
                                    det_list.append(list(int_xyxy))
                                    conf_list.append(conf * 100)
                                    detected_num += 1
                                    info += '排水口{:d}位置：\n'.format(detected_num)
                                    cx, cy = coordinate1.XiangSuCoordinate(img0.shape[1], img0.shape[0], int_xyxy[0],
                                                                           int_xyxy[1])

                                    jb, wb = coordinate1.getLongitudeAndLatitude(cx, cy)

                                    jb_list.append(jb)
                                    wb_list.append(wb)

                                    info += '左上角坐标 ({:d} {:d}) \n右下角坐标 ({:d} {:d})\n'.format(*int_xyxy)
                                    info += '经度 ({:.3f}) \n纬度 ({:.3f})\n'.format(jb[0], wb[0])
                                    info += '置信度：{:.4f}%\n\n'.format(conf * 100)
                                    # print('int_xyxy', int_xyxy)
                                    inxy.append(int_xyxy)
                                    j.append(jb[0])
                                    w.append(wb[0])
                                    plot_one_box(int_xyxy, img0, label=label, color=(0, 0, 255), line_thickness=3)

                # 保存csv
                b = []
                c = []
                for z in range(len(inxy)):
                    b.append(z + 1)
                    c.append(inxy[z])
                dataframe = pd.DataFrame({'疑似排水口数量': detected_num, '排水口序号': b, '图像中排水口位置': c, '排水口经度': j, '排水口纬度': w})
                dataframe.to_csv('template/'+os.path.basename(self.path).split('.')[0] + '.csv', index=False, sep=',',
                                 encoding='gbk')
                print('保存完毕')

                self.lineEdit_3.setText(str(detected_num))
                cv2.imwrite('template/processed.jpg', img0)
                self.textEdit.setText(info)
                self.pixmap = QPixmap('template/processed.jpg')
                # self.scaled_img = self.pixmap.scaled(self.size())
                # self.labelImage.setPixmap(self.pixmap)
                self.labelImage.setPixmap(self.pixmap)
                # self.labelImage.repaint()
                self.labelImage.set_pic()
                # self.labelImage.setPixmap(QPixmap(label_image))#设置显示图片
                print('process end!')

    def getsize(self):
        return self.labelImage.size()

    def pro1(self, N, l):
        # for z in range(len(imgName)):
        img0 = cv2.imdecode(np.fromfile(imgName[l], dtype=np.uint8), cv2.IMREAD_COLOR)
        print('read_img end!')
        # names['info_list_' + str(l)] = ''
        detected_num = 0
        gxyxy = []
        del names['det_list_' + str(l)][N]
        del names['conf_list_' + str(l)][N]
        del names['jb_list_' + str(l)][N]
        del names['wb_list_' + str(l)][N]
        info = ''
        # self.labelImage.set_bbox(det_list)
        if names['det_list_' + str(l)] is not None and len(names['det_list_' + str(l)]):
            num = 0
            # Write results
            for obj_indx, *xyxy in enumerate(names['det_list_' + str(l)]):
                detected_num += 1
                num += 1
                gxyxy.append(xyxy)
                label = str(num)
                print('xyxy',xyxy)
                plot_one_box(xyxy[0], img0, label=label, color=(0, 0, 255), line_thickness=3)
                cv2.imwrite('template/processed_{}.jpg'.format(l+1), img0)
        # 检测结果显示
                info += '排水口{:d}位置：\n'.format(detected_num)
                info += '左上角坐标 ({:d} {:d}) \n右下角坐标 ({:d} {:d})\n'.format(*xyxy[0])
                info += '经度 ({:.3f}) \n纬度 ({:.3f})\n'.format(float(names['jb_list_' + str(l)][detected_num - 1]),
                                                             float(names['wb_list_' + str(l)][detected_num - 1]))
                info += '置信度：{:.4f}%\n\n'.format(names['conf_list_' + str(l)][detected_num - 1])
        elif len(names['det_list_' + str(l)]) == 0:
            cv2.imwrite('template/processed_{}.jpg'.format(l+1), img0)

        names['info_list_' + str(l)] = info
        # 保存csv
        b = []
        c = []
        for z in range(len(names['det_list_' + str(l)])):
            b.append(z + 1)
            c.append(gxyxy[z])
        dataframe = pd.DataFrame(
            {'疑似排水口数量': detected_num, '排水口序号': b, '图像中排水口位置': c, '排水口经度': names['jb_list_' + str(l)], '排水口纬度': names['wb_list_' + str(l)]})
        dataframe.to_csv('template/'+os.path.basename(imgName[l]).split('.')[0] + '.csv', index=False, sep=',', encoding='gbk')
        print('保存完毕', os.path.basename(imgName[l]).split('.')[0] + '.csv')

        self.textEdit.setText(info)
        self.lineEdit_3.setText(str(len(names['det_list_' + str(l)])))
        # 显示图片
        self.pixmap = QPixmap('template/processed_{}.jpg'.format(l+1))
        self.labelImage.setPixmap(self.pixmap)
        print('end!')
    def pro(self, N):
        print(imgName[0], os.path.exists(imgName[0]))
        img0 = cv2.imdecode(np.fromfile(imgName[0], dtype=np.uint8), cv2.IMREAD_COLOR)
        print('read_img end!')
        detected_num = 0
        gxyxy = []
        # pdb.set_trace()
        # det = [[792, 397, 900, 479, 8.92033e-01, 0.00000e+00],
        #        [306, 230, 474, 478, 8.31206e-01, 5.00000e+00],
        #        [600, 406, 700, 479, 8.20242e-01, 0.00000e+00],
        #        [223, 800, 400, 979, 2.51976e-01, 0.00000e+00]]
        del det_list[N]
        del conf_list[N]
        del jb_list[N]
        del wb_list[N]
        info = ''
        # self.labelImage.set_bbox(det_list)
        if det_list is not None and len(det_list):
            num = 0
            # Write results
            for obj_indx, *xyxy in enumerate(det_list):
                detected_num += 1
                num += 1
                gxyxy.append(xyxy[0])
                label = str(num)
                print('xyxy',xyxy)
                plot_one_box(xyxy[0], img0, label=label, color=(0, 0, 255), line_thickness=3)
                cv2.imwrite('template/processed.jpg', img0)
        # 检测结果显示
                info += '排水口{:d}位置：\n'.format(detected_num)
                info += '左上角坐标 ({:d} {:d}) \n右下角坐标 ({:d} {:d})\n'.format(*xyxy[0])
                print('jb_list[]:',jb_list)
                info += '经度 ({:.3f}) \n纬度 ({:.3f})\n'.format(float(jb_list[detected_num-1]), float(wb_list[detected_num-1]))
                print('conf_list:',conf_list)
                info += '置信度：{:.4f}%\n\n'.format(conf_list[detected_num-1])

        # info = '序号  排水口位置\t      排水口经纬度\n'
        # for i in range(len(det_list)):
        #     info += '{:d}  '.format(i + 1)
        #     info += 'X:{0},Y:{1},W:{2},H:{3}\n'.format(gxyxy[i][0], gxyxy[i][1], gxyxy[i][2], gxyxy[i][3])
        elif len(det_list) == 0:
            cv2.imwrite('template/processed.jpg', img0)
        # 保存csv
        b = []
        c = []
        for z in range(len(det_list)):
            b.append(z + 1)
            c.append(gxyxy[z])
        dataframe = pd.DataFrame({'疑似排水口数量': detected_num, '排水口序号': b, '图像中排水口位置': c, '排水口经度': jb_list, '排水口纬度': wb_list})
        dataframe.to_csv('template/'+os.path.basename(self.path).split('.')[0] + '.csv', index=False, sep=',', encoding='gbk')
        print('保存完毕')
        self.textEdit.setText(info)
        self.lineEdit_3.setText(str(len(det_list)))
        # 显示图片
        self.pixmap = QPixmap('template/processed.jpg')
        self.labelImage.setPixmap(self.pixmap)
        print('end!')

    def retranslateUi(self):
        _translate = QtCore.QCoreApplication.translate
        #设置窗口标题
        self.setWindowTitle(_translate("MainWindow", "testLoading"))
    def timerEvent(self, event):
        # print('timestart')
        if self.step >= 100:
            # print('time')
            self.timer.stop()
            self.pushButton_3.setEnabled(True)
            # self.pushButton_3.setText("开始")
            self.pushButton_3.setText("     Prediction Completed    ")
            return
        self.step = self.step + 1
        self.progressBar.setValue(self.step)
        self.push3 = True

    def closeEvent(self, event):
        print('AAAAA')
    # 清理
    def clearfile(self):
        self.pushButton_3.setText("     开始检测    ")
        self.progressBar.setValue(0)
        self.step = 0
        self.pixmap = QPixmap('')
        self.labelImage.setPixmap(self.pixmap)
        _translate = QtCore.QCoreApplication.translate
        #初始化图片名称
        self.label_7.setText(_translate("MainWindow", ''))
        #初始化检测信息
        self.textEdit.setText('')
        #初始化检测数量
        self.lineEdit_3.setText('')
        #初始化列表
        det_list.clear()
        info_list.clear()
        detected_num_list.clear()
        conf_list.clear()
        jb_list.clear()
        wb_list.clear()
        #初始化响应系数
        # self.lineEdit_6.text('')
        # self.detect_num.setText("")
        # self.detect_info.setText("")
        # self.a = True
        self.push3 = False
        self.opened = False
        self.clik = True
        self.save = False
        global a1
        a1 = False

        #清理临时数据
        # os.remove('template')
        if os.path.exists('template')==True:
            shutil.rmtree('template')

    # 保存图片
    def btn_save(self):
        # b = a.split('.')[0]  # 不带后缀的文件名
        # mg = QFileDialog.getSaveFileName(self, 'Save file', os.path.basename(imgName[0]).split('.')[0] + '_after' + '.jpg', 'Image files(*.jpg , *.png)')
        if self.save == True:
            c=QFileDialog.getExistingDirectory(self, 'Save FileDirectory','F:\yingsu/')
            print(c)
            mg = QFileDialog.getSaveFileName(self, 'Save file','F:\yingsu/'+ os.path.basename(imgName[0]).split('.')[0] + '_after' + '.jpg', 'Image files(*.jpg , *.png)')
            print(mg) #('C:/Users/zhangji/Desktop/20200727204602_after.jpg', 'Image files(*.jpg , *.png)')

            print(len(imgName))
            print(imgName[0])
            if mg[0] != '':
                dirt_1, file_name = os.path.split(mg[0])
                print(dirt_1) #C:/Users/zhangji/Desktop
                # namepath = mg[0].replace(os.path.basename(mg[0]), '')
                # print(namepath)
                if len(imgName)<2:
                    # img0 = cv2.imdecode(np.fromfile(imgName[0], dtype=np.uint8), cv2.IMREAD_COLOR)
                    # img4 = cv2.imdecode(np.fromfile('processed.jpg', dtype=np.uint8), cv2.IMREAD_COLOR)
                    img4 = cv2.imread('template/processed.jpg')
                    print('os.path.exists(processed.jpg):',os.path.exists('template/processed.jpg'))
                    # name = path + 图片名字
                    # name = namepath + os.path.basename(imgName[0])
                    # print(name)
                    print('img4.shape',img4.shape)
                    namep = dirt_1 + '/' + os.path.basename(imgName[0]).split('.')[0] + '_after' + '.jpg'
                    # 不支持中文路径
                    # cv2.imwrite(namep, img4)
                    cv2.imwrite(mg[0], img4)
                    print(type(namep))
                    print(namep, 'os.path.exists(namep):', os.path.exists(namep))
                    # shutil.move(os.path.basename(imgName[0]).split('.')[0] + '.csv', dirt_1)
                    shutil.copy('template/'+os.path.basename(imgName[0]).split('.')[0] + '.csv', dirt_1)
                    # 将DataFrame存储为csv,index表示是否显示行名，default=True
                    # dataframe = pd.read_csv(os.path.basename(self.path).split('.')[0] + '.csv')
                    # dataframe.to_csv(dirt_1 + '/' + os.path.basename(imgName[0]).split('.')[0] + '.csv', index=False, sep=',', encoding='gbk')
                    print('保存完毕')
                else:
                    if os.path.exists(dirt_1 + '/processed_image')==False:
                        os.mkdir(dirt_1 + '/processed_image')
                    dirt_1 += '/processed_image'
                    print(len(imgName))
                    for j in range(len(imgName)):
                        # mp[j] =
                        img0 = cv2.imread('template/processed_{:d}.jpg'.format(j+1))
                        # img0 = cv2.imdecode(np.fromfile(imgName[j], dtype=np.uint8), cv2.IMREAD_COLOR)
                        # # name = os.path.basename(imgName[j])
                        # name = namepath + os.path.basename(imgName[j])
                        namep = dirt_1 + '/' + os.path.basename(imgName[j]).split('.')[0] + '_after' + '.jpg'
                        print(namep)
                        print(mg[0])
                        print(os.path.basename(imgName[j]))
                        cv2.imwrite(namep, img0)
                        if os.path.exists(dirt_1 + '/' + os.path.basename(imgName[j]).split('.')[0] + '.csv') == False:
                            # shutil.move(os.path.basename(imgName[j]).split('.')[0] + '.csv', dirt_1)
                            shutil.copy('template/'+os.path.basename(imgName[j]).split('.')[0] + '.csv', dirt_1)
                        print('保存完毕')
        else:
            self.error_dialog = QtWidgets.QErrorMessage()
            self.error_dialog.showMessage('请载入图片或开始检测')
    # 切换图片
    # def skipright(self):
    #     self.pixmap = QPixmap(imgName[1])
    #     self.labelImage.setPixmap(self.pixmap)
    #     self.labelImage.setScaledContents(True)
    #     imgname1 = os.path.basename(imgName[1])  # 图片名称
    #     _translate = QtCore.QCoreApplication.translate
    #     self.label_7.setText(_translate("MainWindow", imgname1))  # 显示图片名称
    #
    #     self.opened = True
    # def skipleft(self):
    #     self.pixmap = QPixmap(imgName[0])
    #     self.labelImage.setPixmap(self.pixmap)
    #     self.labelImage.setScaledContents(True)
    #     imgname1 = os.path.basename(imgName[0])  # 图片名称
    #     _translate = QtCore.QCoreApplication.translate
    #     self.label_7.setText(_translate("MainWindow", imgname1))  # 显示图片名称
    #     self.opened = True
    # 切换图片
    def next(self):
        if self.n + 1 < len(imgName):
            self.n += 1
            print('True')
            print(self.n)
            global N
            N = self.n
            print('N',N)
            if self.a == True:
                self.pixmap = QPixmap(imgName[self.n])
                self.labelImage.setPixmap(self.pixmap)
                self.labelImage.setScaledContents(True)
                imgname1 = os.path.basename(imgName[self.n])  # 图片名称
                _translate = QtCore.QCoreApplication.translate
                self.label_7.setText(_translate("MainWindow", imgname1))  # 显示图片名称
            else:
                self.pixmap = QPixmap('template/processed_{:d}.jpg'.format(self.n+1))
                self.labelImage.setPixmap(self.pixmap)
                self.labelImage.setScaledContents(True)
                imgname1 = os.path.basename('template/processed_{:d}.jpg'.format(self.n+1))  # 图片名称
                _translate = QtCore.QCoreApplication.translate
                self.label_7.setText(_translate("MainWindow", imgname1))  # 显示图片名称
                self.lineEdit_3.setText(str(len(names['det_list_' + str(self.n)])))  # 显示疑似检测数目
                self.textEdit.setText(names['info_list_' + str(self.n)])  # 显示输出信息
                # self.textEdit.setText(info_list[self.n])
            self.opened = True
    def last(self):
        if self.n + 1 > 1:
            self.n -= 1
            print('111'*50)
            print(self.n)
            global N
            N = self.n
            print('N', N)
            if self.a == True:
                self.pixmap = QPixmap(imgName[self.n])
                self.labelImage.setPixmap(self.pixmap)
                self.labelImage.setScaledContents(True)
                imgname1 = os.path.basename(imgName[self.n])  # 图片名称
                _translate = QtCore.QCoreApplication.translate
                self.label_7.setText(_translate("MainWindow", imgname1))  # 显示图片名称
            else:
                self.pixmap = QPixmap('template/processed_{:d}.jpg'.format(self.n+1))
                self.labelImage.setPixmap(self.pixmap)
                self.labelImage.setScaledContents(True)
                imgname1 = os.path.basename('template/processed_{:d}.jpg'.format(self.n+1))  # 图片名称
                _translate = QtCore.QCoreApplication.translate
                self.label_7.setText(_translate("MainWindow", imgname1))  # 显示图片名称
                self.lineEdit_3.setText(str(len(names['det_list_' + str(self.n)])))  # 显示疑似检测数目
                # self.textEdit.setText(info_list[self.n])  # 显示输出信息
                self.textEdit.setText(names['info_list_' + str(self.n)])
            self.opened = True
    def rep(self, path):
        self.pixmap = QPixmap(path)
        self.labelImage.setPixmap(self.pixmap)
        self.labelImage.setScaledContents(True)
    # 批量图片
    def openimage(self):
        if self.clik == True:
            global imgName, a1
            a1 = False
            # if self.lineEdit_6.text() == '' or is_number(self.lineEdit_6.text()) == False:
            #     self.error_dialog = QtWidgets.QErrorMessage()
            #     self.error_dialog.showMessage('请输入正确的响应系数!')
            # else:
            # global imgName,a1
            times = 0
            # a1 = True
            self.labelImage.grabKeyboard()  # 控件开始捕获键盘
            # self.labelImage.releaseKeyboard()  # 停止捕获键盘
            # pdb.set_trace()
            imgName, imgType = QtWidgets.QFileDialog.getOpenFileNames(self, "多文件选择", "", "Image files(*.jpg , *.jpeg)")
            if len(imgName) < 2:
                print('必须载入图像张数≥2!')
                # self.error_dialog = QtWidgets.QErrorMessage()
                # self.error_dialog.showMessage('必须载入图像张数≥2!')
            else:
                a1 = True
                self.pixmap = QPixmap(imgName[times]) # 贴图片
                # self.pixmap = self.pixmap.scaled(600, 500, QtCore.Qt.KeepAspectRatio)
                for i in range(len(imgName)):
                    self.path = imgName[i]
                    print(self.path)
                self.labelImage.setPixmap(self.pixmap)
                self.labelImage.setScaledContents(True)

                imgname1 = os.path.basename(imgName[times]) # 图片名称
                _translate = QtCore.QCoreApplication.translate
                self.label_7.setText(_translate("MainWindow", imgname1)) # 显示图片名称
                # self.detect_num.setText("")
                # self.detect_info.setText("")
                # print(openfile_name)
                self.opened = True
                self.clik = False
                # self.pushButton_6.setEnabled(True)
                # self.pushButton_7.setEnabled(True)
        else:
            self.error_dialog = QtWidgets.QErrorMessage()
            self.error_dialog.showMessage('请清除图片或者开始检测！')
    # 打开单张图片
    def openfile(self):
        if self.clik == True:
            global imgName, a1
            a1 = False

            # if self.lineEdit_6.text() == '' or is_number(self.lineEdit_6.text()) == False:
            #     self.error_dialog = QtWidgets.QErrorMessage()
            #     self.error_dialog.showMessage('请输入正确的响应系数!')
            # else:

            # a1 = True
            # pdb.set_trace()
            self.labelImage.grabKeyboard()  # 控件开始捕获键盘

            # imgName = QFileDialog.getOpenFileName(self, '选择文件', '', 'Image files(*.jpg , *.jpeg)')
            imgName, imgType = QtWidgets.QFileDialog.getOpenFileNames(self, "文件选择", "", "Image files(*.jpg , *.jpeg)")
            # openfile_name = QFileDialog.getOpenFileName(self, '选择文件', '', 'Image files(*.jpg , *.jpeg)')
            print('len(imgName)',len(imgName))
            if len(imgName) != 1:
                print('必须载入图像张数≥2!')
                # self.error_dialog = QtWidgets.QErrorMessage()
                # self.error_dialog.showMessage('必须载入图像张数为1!')
            else:
                a1 = True
                self.pixmap = QPixmap(imgName[0])
                # self.pixmap = self.pixmap.scaled(600, 500, QtCore.Qt.KeepAspectRatio)
                self.path = imgName[0]
                print(self.path)
                self.labelImage.setPixmap(self.pixmap)
                self.labelImage.setScaledContents(True)

                imgname = os.path.basename(imgName[0])
                _translate = QtCore.QCoreApplication.translate
                self.label_7.setText(_translate("MainWindow", imgname))
                # self.detect_num.setText("")
                # self.detect_info.setText("")
                # print(openfile_name)
                self.opened = True
                self.clik = False
        else:
            self.error_dialog = QtWidgets.QErrorMessage()
            self.error_dialog.showMessage('请清除图片或者开始检测！')
    def switch_pic(self, imgName):
        self.n += 1
        self.pixmap = QPixmap(imgName)
        # self.pixmap = self.pixmap.scaled(600, 500, QtCore.Qt.KeepAspectRatio)
        self.path = imgName
        print(self.path)
        self.labelImage.setPixmap(self.pixmap)
        self.labelImage.setScaledContents(True)
        self.labelImage.repaint()

        imgname = os.path.basename(imgName)
        _translate = QtCore.QCoreApplication.translate
        self.label_7.setText(_translate("MainWindow", imgname))
        # self.detect_num.setText("")
        # self.detect_info.setText("")
        # print(openfile_name)
        self.opened = True

    def retranslateUi(self, MainWindow):
        _translate = QtCore.QCoreApplication.translate
        MainWindow.setWindowTitle(_translate("MainWindow", "The Intelligent Outfall Detection Software"))
        self.label.setText(_translate("MainWindow", "<html><head/><body><p align=\"center\"><span style=\" font-size:0pt;\"> </span></p ></body></html>"))
        self.label_2.setText(_translate("MainWindow", "Detection Progress:"))
        self.label_3.setText(_translate("MainWindow", "Response Factor:"))
        self.label_4.setText(_translate("MainWindow", "Image Name:"))
        # self.label_4.setText(_translate("MainWindow", "推理速度FPS:"))
        self.label_5.setText(_translate("MainWindow", "Suspected Outfalls:"))
        self.label_6.setText(_translate("MainWindow", "Detection Results:"))
        self.pushButton.setText(_translate("MainWindow", "Batch Image Processing"))
        self.pushButton_2.setText(_translate("MainWindow", "Single Image Processing"))
        self.pushButton_3.setText(_translate("MainWindow", "Star"))
        self.pushButton_4.setText(_translate("MainWindow", "Clear"))
        self.pushButton_5.setText(_translate("MainWindow", "Save"))
        MainWindow.setWindowIcon(QIcon("32.ico"))

N = 0
det_list = []
info_list = []
detected_num_list = []
conf_list = []
jb_list = []
wb_list = []
a1 = False

# 程序调用接口
def API(input,output):
    model = ONNX(onnx_path="super_resolution.onnx")
    model.infer(input,output)


class draw_Label(QLabel, Ui_MainWindow):
    def __init__(self, parent=None, main_window=None):
        super(draw_Label, self).__init__(parent)
        self.parent = parent
        self.point = QPoint(0, 0)
        self.main_window = main_window

    def set_pic(self):
        # self.img = img
        # self.setPixmap(self.img)
        # self.repaint()
        print('repaint')
        self.point = QPoint(0, 0)
        # 重画
        self.scaled_img = self.pixmap().scaled(self.size())
        self.repaint()

    def set_bbox(self, bbox):
        self.bbox = bbox

    def clear_bbox(self):
        self.bbox = None

    def paintEvent(self, e):
        '''
        绘图
        :param e:
        :return:
        '''
        painter = QPainter()
        painter.begin(self)
        self.draw_img(painter, e)
        painter.end()

    def draw_img(self, painter, e):
        # pass
        if (self.scaled_img.width() < 10 or self.scaled_img.height() < 10) \
                or (self.pixmap().height() == 0 or self.pixmap().width() == 0):
            print('paint origin img')
            self.scaled_img = self.pixmap().scaled(self.size())
            self.point = QPoint(0, 0)
            painter.drawPixmap(self.point, self.scaled_img)
        else:
            print('paint scaled img')
            painter.drawPixmap(self.point, self.scaled_img)

    def mouseMoveEvent(self, e):  # 重写移动事件
        if self.left_click:
            self._endPos = e.pos() - self._startPos
            self.point = self.point + self._endPos
            self._startPos = e.pos()
            self.repaint()
            # print('self._endPos={:d}'.format(self._endPos))

    def mouseDoubleClickEvent(self, e):
        print("双击")
        global a1
        if a1 == False or self.scaled_img.width()==0:
            print('请载入图片!')
        else:
            img = Image.open(imgName[0])
            # print(img.width)
            # print(img.size)
            # print('img',img.pos().x())
            print('鼠标X：', e.pos().x())
            print('鼠标Y：', e.pos().y())
            # det = [[792.0, 397.0, 900.0, 479.0, 8.92033e-01, 0.00000e+00],
            #        [306, 230, 474, 478, 8.31206e-01, 5.00000e+00],
            #        [600, 406, 700, 479, 8.20242e-01, 0.00000e+00],
            #        [223, 800, 400, 979, 2.51976e-01, 0.00000e+00]]
            # 窗口哔哩
            # self.x = img.width / self.scaled_img.width()
            # self.y = img.height / self.scaled_img.height()
            # a = self.x * e.pos().x() - self.point.x() * self.x
            # b = self.y * e.pos().y() - self.point.y() * self.y
            if len(imgName) > 1:
                for l in range(len(imgName)):
                    img = Image.open(imgName[l])
                    self.x = img.width / self.scaled_img.width()
                    self.y = img.height / self.scaled_img.height()
                    a = self.x * e.pos().x() - self.point.x() * self.x
                    b = self.y * e.pos().y() - self.point.y() * self.y
                    for i, element in enumerate(names['det_list_' + str(l)]):
                        if l == N and a > names['det_list_' + str(l)][i][0] and a < names['det_list_' + str(l)][i][2] and b > names['det_list_' + str(l)][i][1] and b < names['det_list_' + str(l)][i][3]:
                            print('选中{:d}'.format(i + 1))
                            self.main_window.pro1(i, l)
            else:
                img = Image.open(imgName[0])
                self.x = img.width / self.scaled_img.width()
                self.y = img.height / self.scaled_img.height()
                a = self.x * e.pos().x() - self.point.x() * self.x
                b = self.y * e.pos().y() - self.point.y() * self.y
                for i, element in enumerate(det_list):
                    if a > det_list[i][0] and a < det_list[i][2] and b > det_list[i][1] and b < det_list[i][3]:
                        print('选中{:d}'.format(i + 1))
                        self.main_window.pro(i)
            # if a > det[0][0] and a < det[0][2] and b > det[0][1] and b < det[0][3]:
            #     print('选中1')
            #     self.main_window.pro(0)
            # elif a > det[1][0] and a < det[1][2] and b > det[1][1] and b < det[1][3]:
            #     print('选中2')
            #     self.main_window.pro(1)
            # elif a > det[2][0] and a < det[2][2] and b > det[2][1] and b < det[2][3]:
            #     print('选中3')
            #     self.main_window.pro(2)
            # elif a > det[3][0] and a < det[3][2] and b > det[3][1] and b < det[3][3]:
            #     print('选中4')
            #     self.main_window.pro(3)

            self.scaled_img = self.pixmap().scaled(self.scaled_img.size())
            self.repaint()

    def mousePressEvent(self, e):
        if e.button() == Qt.LeftButton:
            self.left_click = True
            self._startPos = e.pos()
            print('点击左键')
            print('det_list', det_list)
        elif e.button() == Qt.RightButton:
            print('点击右键')

    def mouseReleaseEvent(self, e):
        if e.button() == Qt.LeftButton:
            global a1
            print('a1',a1)
            if a1 == False:
                print('请载入图片!')
                # self.error_dialog = QtWidgets.QErrorMessage()
                # self.error_dialog.showMessage('mouseDoubleClickEvent!')
            else:
                img = Image.open(imgName[0])
                # print(img.width)
                # print('self._endPos', self._endPos.x())
                # print('self._endPos', self._endPos.y())
                print('self.point', self.point.x())
                print('self.point', self.point.y())
                print('原始图像大小：', img.size)
                print('画布大小：', self.main_window.getsize())
                print('缩放图片大小:', self.scaled_img.size())
                print('鼠标X：', e.pos().x())
                print('鼠标Y：', e.pos().y())
                print('Qpointx：', self._startPos.x())
                print('Qpointy：', self._startPos.y())
                # det = [[792.0, 397.0, 900.0, 479.0, 8.92033e-01, 0.00000e+00],
                #        [306, 230, 474, 478, 8.31206e-01, 5.00000e+00],
                #        [600, 406, 700, 479, 8.20242e-01, 0.00000e+00],
                #        [223, 800, 400, 979, 2.51976e-01, 0.00000e+00]]
                # 窗口哔哩
                # self.x = e.pos().x()/self.main_window.getsize().width()
                # self.y = e.pos().y()/self.main_window.getsize().height()
                # print('self.x：', self.x * img.size[0])
                # print('self.y：', self.y * img.size[1])
                # 图片缩放比例
                print(self.scaled_img.width())
                if self.scaled_img.width() == 0:
                    print('请载入图片!')
                    # self.error_dialog = QtWidgets.QErrorMessage()
                    # self.error_dialog.showMessage('请载入图片!')
                else:
                    self.x = img.width / self.scaled_img.width()
                    self.y = img.height / self.scaled_img.height()
                    print('self.x：', self.x * e.pos().x() - self.point.x() * self.x)
                    print('self.y：', self.y * e.pos().y() - self.point.y() * self.y)
                    a = self.x * e.pos().x() - self.point.x() * self.x
                    b = self.y * e.pos().y() - self.point.y() * self.y
                    if len(imgName) > 1:
                        for l in range(len(imgName)):
                            img = Image.open(imgName[l])
                            print('-'*50)
                            print('l',l)
                            A = N
                            print('N',A)
                            self.x = img.width / self.scaled_img.width()
                            self.y = img.height / self.scaled_img.height()
                            a = self.x * e.pos().x() - self.point.x() * self.x
                            b = self.y * e.pos().y() - self.point.y() * self.y
                            for i, element in enumerate(names['det_list_' + str(l)]):
                                if A == l and a > names['det_list_' + str(l)][i][0] and a < names['det_list_' + str(l)][i][2] and b > names['det_list_' + str(l)][i][1] and b < names['det_list_' + str(l)][i][3]:
                                    print('选中det_list_{}='.format(l))
                                    print('det_list_{}'.format(l),names['det_list_' + str(l)])
                                    print('选中{:d}'.format(i + 1))
                                    # self.main_window.process()
                                    xyxy = names['det_list_' + str(l)][i][0:4]
                                    xyxy = torch.tensor(xyxy)
                                    imgP = 'template/processed_{}.jpg'.format(l+1)
                                    img = cv2.imdecode(np.fromfile(imgP, dtype=np.uint8), cv2.IMREAD_COLOR)
                                    f = str(i + 1)
                                    plot_one_box(xyxy, img, label=f, color=(0, 255, 0), line_thickness=3)
                                    cv2.imwrite('template/processed1_{}.jpg'.format(l+1), img)
                                    self.main_window.rep('template/processed1_{}.jpg'.format(l+1))
                    else:
                        img = Image.open(imgName[0])
                        self.x = img.width / self.scaled_img.width()
                        self.y = img.height / self.scaled_img.height()
                        a = self.x * e.pos().x() - self.point.x() * self.x
                        b = self.y * e.pos().y() - self.point.y() * self.y
                        for i, element in enumerate(det_list):
                            if a > det_list[i][0] and a < det_list[i][2] and b > det_list[i][1] and b < det_list[i][3]:
                                print('选中{:d}'.format(i + 1))
                                # self.main_window.process()
                                xyxy = det_list[i][0:4]
                                xyxy = torch.tensor(xyxy)
                                # if  os.path.exists('processed2.jpg') == True:
                                #     imgP = 'processed2.jpg'
                                # else:
                                #     imgP = 'processed.
                                imgP = 'template/processed.jpg'
                                img = cv2.imdecode(np.fromfile(imgP, dtype=np.uint8), cv2.IMREAD_COLOR)
                                f = str(i + 1)
                                plot_one_box(xyxy, img, label=f, color=(0, 255, 0), line_thickness=3)
                                cv2.imwrite('template/processed1.jpg', img)
                                self.main_window.rep('template/processed1.jpg')


                    self.scaled_img = self.pixmap().scaled(self.scaled_img.size())
                    self.repaint()

                    self.left_click = False
        elif e.button() == Qt.RightButton:
            self.point = QPoint(0, 0)
            # 重画
            self.scaled_img = self.pixmap().scaled(self.size())
            self.repaint()

    def wheelEvent(self, e):
        print('屏幕鼠标X：', QCursor.pos().x())
        print('屏幕鼠标Y：', QCursor.pos().y())
        if e.angleDelta().y() > 0:
            # 放大图片
            self.scaled_img = self.pixmap().scaled(self.scaled_img.width() - 100, self.scaled_img.height() - 100)
            new_w = e.x() - (self.scaled_img.width() * (e.x() - self.point.x())) / (self.scaled_img.width() + 100)
            new_h = e.y() - (self.scaled_img.height() * (e.y() - self.point.y())) / (self.scaled_img.height() + 100)
            self.point = QPoint(new_w, new_h)
            self.repaint()
        elif e.angleDelta().y() < 0:
            # 缩小图片
            self.scaled_img = self.pixmap().scaled(self.scaled_img.width() + 100, self.scaled_img.height() + 100)
            print(self.pixmap().toImage().size(), self.scaled_img.size())
            new_w = e.x() - (self.scaled_img.width() * (e.x() - self.point.x())) / (self.scaled_img.width() - 100)
            new_h = e.y() - (self.scaled_img.height() * (e.y() - self.point.y())) / (self.scaled_img.height() - 100)
            self.point = QPoint(new_w, new_h)
            self.repaint()

    def resizeEvent(self, e):
        if self.parent is not None:
            self.scaled_img = self.pixmap().scaled(self.size())
            self.point = QPoint(0, 0)
            self.update()

    def returnsize(self):
        return self.scaled_img.size()

    def keyPressEvent(self, QKeyEvent):  # 键盘某个键被按下时调用
        # 参数1  控件
        # self.labelImage.grabKeyboard()  # 控件开始捕获键盘
        if QKeyEvent.key() == Qt.Key_A:  # 判断是否按下了A键
            # key()  是普通键
            print('按下了A')
            print('鼠标X：', QCursor.pos().x())
            print('鼠标Y：', QCursor.pos().y())
            print('tupianX：', self.pos().x())
            print('tupianY：', self.pos().y())
            print('tupianX：', self.main_window.x())
            print('tupianY：', self.main_window.y())
            print('chuankouX：', self.parent.pos().x())
            print('chuankouY：', self.parent.pos().y())

        if QKeyEvent.key() == Qt.Key_Left:
            print('按下了左键')
            self.main_window.last()

        if QKeyEvent.key() == Qt.Key_Right:
            print('按下了右键')
            self.main_window.next()

        self.scaled_img = self.pixmap().scaled(self.size())
        self.repaint()

    def closeEvent(self, event):
        reply = QMessageBox(QMessageBox.Question, self.tr("提示"),
                            self.tr("最小化界面还是关闭界面"), QtWidgets.QMessageBox.NoButton, self)
        yr_btn = reply.addButton(self.tr("关闭界面"), QtWidgets.QMessageBox.YesRole)
        reply.addButton(self.tr("最小化界面"), QtWidgets.QMessageBox.NoRole)
        reply.exec_()
        if reply.clickedButton() == yr_btn:
            event.accept()
            QtWidgets.qApp.quit()
        # sys.exit(app.exec_())
        else:
            event.ignore()
    # 最小化到托盘

if __name__ == '__main__':
    # input = r'F:\psk_code\image\20200727204533.jpg'
    # output = r"result.jpg"
    # API(input,output)

    app = QApplication(sys.argv)
    # 创建一个主窗口
    mainWindow = QMainWindow()
    # ui实例化
    ui = Ui_MainWindow()
    # 讲窗口传递进去，让Ui_MainWindow向主窗口上放置组件
    ui.setupUi(mainWindow)
    # 显示
    mainWindow.show()
    # 主循环
    sys.exit(app.exec_())


